---
title: "Feudal Latent Space Exploration for Coordinated Multi-agent Reinforcement Learning"
collection: publications
permalink: /publications/FLE
excerpt: "Feudal Latent Space Exploration for Coordinated Multi-agent Reinforcement Learning."
date: 2020-05-09
venue: "AAMAS@ALA"
year: 2020
paperurl: "https://ala2020.vub.ac.be/papers/ALA2020_paper_22.pdf"
authorlist: "Xiangyu Liu, Ying Tan"
citation: "Xiangyu Liu and Ying Tan. 2020. Feudal Latent Space Exploration for Coordinated Multi-agent Reinforcement Learning. In Adaptive and Learning Agents Workshop at International Conference on Autonomous Agents and Multi-Agent Systems(AAMAS) 2020, 8 pages."
status: 'pub'
---
**Abstract:**
We investigate how multiple agents learn to coordinate to form efficient exploration in reinforcement learning. Though straightforward, independent exploration of the joint action space of multiple agents will become exponentially more difficult as the number of agents increases. To tackle this problem, we propose Feudal Latentspace Exploration (FLE) for Multi-agent Reinforcement Learning. FLE introduces a feudal commander to learn a low-dimensional global latent structure that instructs multiple agents to explore coordinately. Under this framework, the multi-agent policy gradient is adopted to optimize both the agent policy and latent structure end-to-end. We demonstrate the effectiveness of this method in two multi-agent environments which need explicit coordination. Experimental results validate that FLE outperforms baseline MARL approaches which use independent exploration strategy in terms of mean rewards, efficiency, as well as the expressiveness of coordination policies.

**Download: [[PDF]](https://ala2020.vub.ac.be/papers/ALA2020_paper_22.pdf)**\
