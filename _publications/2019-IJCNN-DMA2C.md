---
title: "Learning Distributed Coordinated Policy in Catching Game with Multi-Agent Reinforcement Learning"
collection: publications
permalink: /publications/DMA2C
excerpt: "Learning Distributed Coordinated Policy in Catching Game with Multi-Agent Reinforcement Learning"
date: 2019-09-30
venue: "IJCNN"
year: 2019
paperurl: "https://ieeexplore.ieee.org/document/8851905"
authorlist: "Xiangyu Liu, Ying Tan"
citation: "Xiangyu Liu and Ying Tan. 2019. Learning Distributed Coordinated Policy in Catching Game with Multi-Agent Reinforcement Learning. 2019 International Joint Conference on Neural Networks (IJCNN), Budapest, Hungary, 2019, pp. 1-7, doi: 10.1109/IJCNN.2019.8851905."
status: 'pub'
---
**Abstract:**
Although learning-based methods such as reinforcement learning have been applied to multi-agent systems design successfully, it is still difficult to learn efficient coordinated policies for agents in partially observed environment settings. Centralized learners contain much more information, but add more complexity, while independent learners suffer from partial observation. To address these problems, we propose a directed multi-agent actor-critic algorithm to directly learn the coordinated policy from experience. The directed critic model can obtain all information including global information and actions, which provides effective learning signals for distributed learning actors. We take Multi-Agent Catching Game as the test scenario, where the task is to coordinate multiple moving paddles to catch balls dropping from the top of the screen. We perform several experimental evaluations and show that our method leads to superior results in learning performance, coordination effect and scalability, compared with both centralized and independent learning approach.

**Download: [[PDF]](https://www.cil.pku.edu.cn/docs/2019-11/20191106130918574122.pdf)**
